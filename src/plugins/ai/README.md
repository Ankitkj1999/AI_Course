# Milkdown AI Plugin

Proper Milkdown plugin integration for AI assistance, leveraging the existing LLM infrastructure.

## Architecture

This implementation follows Milkdown's plugin architecture and integrates with the sophisticated backend LLM service (`server/services/llmService.js`).

### Key Components

- **`index.ts`** - Core plugin with proper Milkdown integration
  - `MilkdownAIUtils` - Editor utilities for text selection and insertion
  - `createAISlashMenuConfig()` - Slash menu configuration
  - `createAIToolbarConfig()` - Toolbar configuration

- **`ui/AIModal.tsx`** - React modal component with keyboard navigation
  - Context-aware options (modify vs generate)
  - Custom prompt support
  - Loading states and error handling

- **`hooks/useAIModal.ts`** - Modal state management
  - Separates UI state from editor logic
  - Clean open/close lifecycle

- **`src/services/llmService.ts`** - Frontend bridge to backend LLM service
  - Connects to `server/services/llmService.js`
  - Leverages multi-provider support (Gemini, OpenAI, etc.)
  - Health checks and fallback mechanisms
  - Comprehensive logging and monitoring

## Features

âœ… **Proper Milkdown Integration**
- Uses Milkdown's context system correctly
- Proper ProseMirror state access
- Transaction-based text manipulation

âœ… **Backend LLM Infrastructure**
- Multi-provider support with automatic fallback
- Health monitoring and performance metrics
- Comprehensive error handling
- Request logging with unique IDs

âœ… **Context-Aware UI**
- Different options for selected text vs empty cursor
- Keyboard navigation (â†‘â†“ to navigate, Enter to select, Esc to close)
- Loading states and error feedback

âœ… **TypeScript Safety**
- Proper type definitions for ProseMirror
- No `any` types in critical paths
- Type-safe editor operations

## Usage

### In TestPlate.tsx

```typescript
import { 
  milkdownAIUtils, 
  createAISlashMenuConfig, 
  createAIToolbarConfig 
} from '../plugins/ai';
import { llmService } from '../services/llmService';

// Create handlers
const handleToolbarAI = () => {
  const selectedText = milkdownAIUtils.getSelectedText();
  openModal('toolbar', selectedText);
};

const handleSlashMenuAI = () => {
  openModal('slash-menu');
};

// Configure Crepe
const crepe = new Crepe({
  featureConfigs: {
    [Crepe.Feature.BlockEdit]: createAISlashMenuConfig(handleSlashMenuAI),
    [Crepe.Feature.Toolbar]: createAIToolbarConfig(handleToolbarAI),
  },
});

// Initialize AI utilities
crepe.create().then(() => {
  milkdownAIUtils.setCrepe(crepe);
});

// Execute AI
const result = await llmService.generateContent(prompt, {
  temperature: 0.7,
  preferFree: true,
});

if (result.success) {
  milkdownAIUtils.replaceSelectedText(result.data.content);
}
```

## API

### MilkdownAIUtils

```typescript
class MilkdownAIUtils {
  setCrepe(crepe: Crepe): void
  getSelectedText(): string
  replaceSelectedText(text: string): boolean
  insertAtCursor(text: string): boolean
  getCursorContext(): { hasSelection: boolean; position: number }
}
```

### LLM Service

```typescript
interface LLMGenerateOptions {
  provider?: string;
  model?: string;
  temperature?: number;
  preferFree?: boolean;
}

llmService.generateContent(prompt: string, options?: LLMGenerateOptions): Promise<LLMResponse>
llmService.getProviders(): Promise<Provider[]>
llmService.checkHealth(): Promise<HealthStatus>
```

## Context-Aware Options

### Toolbar Actions (Selected Text)
- âœ¨ Improve writing - Enhance clarity and style
- ğŸ“ Make longer - Add more details and examples
- âœ‚ï¸ Make shorter - Condense while keeping key points
- ğŸ”¤ Simplify language - Use easier words and structure
- âœ“ Fix grammar - Correct spelling and grammar

### Slash Menu Actions (New Content)
- âœï¸ Continue writing - Extend from current content
- ğŸ“‹ Create summary - Summarize key points
- ğŸ’¡ Generate ideas - Brainstorm related concepts
- ğŸ“ Write introduction - Create an opening paragraph
- ğŸ¯ Write conclusion - Create a closing paragraph

## What Was Fixed

### Before (Broken Implementation)
- âŒ Fake "plugin" files that were just config objects
- âŒ Duplicate `aiService.ts` bypassing LLM infrastructure
- âŒ Incorrect editor state access causing TypeScript errors
- âŒ Logic hardcoded in TestPlate.tsx
- âŒ No integration with existing logging/monitoring

### After (Proper Implementation)
- âœ… Real Milkdown integration using proper context system
- âœ… Connects to existing `llmService` with all its features
- âœ… Type-safe ProseMirror operations
- âœ… Reusable utilities separated from UI
- âœ… Full integration with backend infrastructure

## Future Enhancements

- [ ] Streaming responses for real-time generation
- [ ] Custom prompt templates
- [ ] AI command history
- [ ] Provider selection UI
- [ ] Batch operations on multiple selections
